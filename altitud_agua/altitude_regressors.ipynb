{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Regression for altitude values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load data from xls files\n",
    "Return *X* values of shape (100, 11) and *y* shape (100, 1).\n",
    "*X* correspond to 11 bands (700, 705, 710, 725, 740, 750, 820, 840, 870, 876, 892) of 100 samples (all transects).\n",
    "\n",
    "*y* correspond to altitude of the samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def load_data(filename=\"data/data_x01.xlsx\"):\n",
    "    transectas = ['transecta_F', 'transecta_E', 'transecta_B', 'transecta_C', 'transecta_D']\n",
    "    appended_df = pd.DataFrame(columns=[])\n",
    "    for transecta in transectas:\n",
    "        df = pd.read_excel(filename, sheetname=transecta)\n",
    "        df = df.iloc[1:]\n",
    "        df = df.transpose()\n",
    "        df.columns = df.iloc[0]\n",
    "        df = df.iloc[1:]\n",
    "        df = df.dropna(axis=1)\n",
    "        # print(df.columns)\n",
    "        df2 = df.copy()\n",
    "        appended_df = appended_df.append([df2])\n",
    "\n",
    "    appended_df.columns.name = 'Puntos'\n",
    "    # print(appended_df)\n",
    "    y = appended_df.iloc[:, -1].values\n",
    "    X = appended_df.iloc[:, :-1].values\n",
    "    \n",
    "    return X, y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12692.0 13385.0 13865.0 ... 14611.0 14063.0 14391.0]\n",
      " [11598.0 12544.0 12551.0 ... 8576.0 7523.0 7200.0]\n",
      " [11235.0 11637.0 11905.0 ... 5902.0 5511.0 5463.0]\n",
      " ...\n",
      " [9878.0 10032.0 10401.0 ... 4777.0 4581.0 4425.0]\n",
      " [11518.0 12099.0 12500.0 ... 7385.0 6733.0 6741.0]\n",
      " [11066.0 11854.0 12037.0 ... 5861.0 5515.0 5247.0]] [4.51344 4.51344 4.34834 4.18328 4.18328 4.01821 3.85315 3.85315 3.68809\n",
      " 3.52309 3.35802 3.35802 3.19296 3.0279 2.86284 2.69777 2.69777 2.45919\n",
      " 4.34834 2.29412 4.51344 4.34831 4.34831 4.18319 4.18319 4.01806 4.01806\n",
      " 3.85298 3.68792 3.52285 3.52285 3.35779 3.19279 3.02772 2.86266 2.86266\n",
      " 2.6976 2.53254 2.43784 2.28407 4.11813 3.953 3.78788 3.49438 3.24886\n",
      " 3.15723 3.06561 2.88236 2.79073 2.6558 2.56417 3.62275 2.542 3.34048\n",
      " 2.542 2.542 2.542 3.15723 2.97398 3.953 4.41469 4.41469 4.24957 3.93055\n",
      " 3.93055 3.71055 3.61892 3.0223 2.69217 2.36205 3.80217 3.71055 3.5273\n",
      " 3.43567 3.27281 2.85723 2.52711 2.52711 2.35577 2.35577 4.55674 4.55674\n",
      " 3.8593 3.8593 3.69423 3.52917 3.52917 3.44372 3.27865 3.15723 3.15723\n",
      " 3.06561 3.69423 2.97398 2.88236 2.79073 2.52711 2.36205 4.54613 3.8593]\n"
     ]
    }
   ],
   "source": [
    "X, y = load_data(\"data/data_x3.xlsx\")\n",
    "assert X.shape == (100, 11) and y.shape == (100,)\n",
    "print(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run metrics for all the neighborhoods's sizes\n",
    "Default 3-fold cross validation using $r^2$ (mean and std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "neighborhoods = [\"data_x01.xlsx\", \"data_x3.xlsx\", \"data_x5.xlsx\", \"data_x7.xlsx\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An extremely randomized tree regressor.\n",
    "Extra-trees differ from classic decision trees in the way they are built. When looking for the best split to separate the samples of a node into two groups, random splits are drawn for each of the max_features randomly selected features and the best split among those is chosen.(http://scikit-learn.org/stable/modules/generated/sklearn.tree.ExtraTreeRegressor.html#sklearn.tree.ExtraTreeRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for data data_x01.xlsx: 0.67 (+/- 0.27)\n",
      "Accuracy for data data_x3.xlsx: 0.82 (+/- 0.04)\n",
      "Accuracy for data data_x5.xlsx: 0.80 (+/- 0.05)\n",
      "Accuracy for data data_x7.xlsx: 0.82 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "for n in neighborhoods:\n",
    "    X, y = load_data('data/' + n)\n",
    "    reg_tree = ExtraTreesRegressor()\n",
    "    scores = cross_val_score(reg_tree, X, y, cv=3)\n",
    "    print(\"Accuracy for data %s: %0.2f (+/- %0.2f)\" % (n, scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_importances(reg_tree):\n",
    "    importances = reg_tree.feature_importances_\n",
    "    # std = np.std([tree.feature_importances_ for tree in reg_tree.estimators_],\n",
    "    #         axis=0)\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    print(\"Feature ranking:\")\n",
    "    for f in range(X.shape[1]):\n",
    "        print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "    # Plot the feature importances of the forest\n",
    "    fig = plt.figure()\n",
    "    plt.title(\"Feature importances\")\n",
    "    plt.bar(range(X.shape[1]), importances[indices],\n",
    "           color=\"r\", align=\"center\")\n",
    "    plt.xticks(range(X.shape[1]), indices)\n",
    "    plt.xlim([-1, X.shape[1]])\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExtraTreesRegressor(bootstrap=False, criterion='mse', max_depth=None,\n",
      "          max_features='auto', max_leaf_nodes=None,\n",
      "          min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "          min_samples_leaf=1, min_samples_split=2,\n",
      "          min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "          oob_score=False, random_state=None, verbose=0, warm_start=False)\n",
      "Feature ranking:\n",
      "1. feature 1 (0.319288)\n",
      "2. feature 2 (0.175631)\n",
      "3. feature 10 (0.093800)\n",
      "4. feature 5 (0.090551)\n",
      "5. feature 3 (0.068868)\n",
      "6. feature 0 (0.058331)\n",
      "7. feature 7 (0.051780)\n",
      "8. feature 9 (0.050946)\n",
      "9. feature 4 (0.041794)\n",
      "10. feature 6 (0.027789)\n",
      "11. feature 8 (0.021223)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSEI/IqIiCf2IiIok9CMiKvL/AYl5YTTLqZv/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe1778647b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8032820926679116"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "X, y = load_data('data/data_x3.xlsx')\n",
    "reg_tree = ExtraTreesRegressor()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(reg_tree.fit(X_train, y_train))\n",
    "plot_importances(reg_tree)\n",
    "plt.show()\n",
    "r2_score(y_test, reg_tree.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVR\n",
    "\n",
    "Epsilon-Support Vector Regression using kernel rbf (http://scikit-learn.org/stable/modules/svm.html#svm-regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for data data_x01.xlsx: -0.22 (+/- 0.31)\n",
      "Accuracy for data data_x3.xlsx: -0.22 (+/- 0.30)\n",
      "Accuracy for data data_x5.xlsx: -0.22 (+/- 0.31)\n",
      "Accuracy for data data_x7.xlsx: -0.22 (+/- 0.31)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "for n in neighborhoods:\n",
    "    X, y = load_data('data/' + n)\n",
    "    svr = SVR(kernel='rbf', C=1e3, gamma=0.1)\n",
    "    scores = cross_val_score(svr, X, y, cv=3)\n",
    "    print(\"Accuracy for data %s: %0.2f (+/- %0.2f)\" % (n, scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Multiple Linear Regression\n",
    "$\\hat{y}$ is the predicted value:\n",
    "\n",
    "$\\hat{y}(w, x) = w_0 + w_1 x_1 + ... + w_p x_p$\n",
    "\n",
    "the vector $w = (w_1,\\cdots, w_p)$ as *coef_* and $w_0$ as *intercept_*\n",
    "\n",
    "from the docs (http://scikit-learn.org/stable/modules/linear_model.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for data data_x01.xlsx: 0.49 (+/- 0.37)\n",
      "Accuracy for data data_x3.xlsx: 0.25 (+/- 0.30)\n",
      "Accuracy for data data_x5.xlsx: -0.01 (+/- 0.22)\n",
      "Accuracy for data data_x7.xlsx: 0.06 (+/- 0.71)\n"
     ]
    }
   ],
   "source": [
    "for n in neighborhoods:\n",
    "    X, y = load_data('data/' + n)\n",
    "    reg = linear_model.LinearRegression(fit_intercept=True)\n",
    "    scores = cross_val_score(reg, X, y, cv=3)\n",
    "    print(\"Accuracy for data %s: %0.2f (+/- %0.2f)\" % (n, scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TheilSenRegressor\n",
    "Theil-Sen Estimator: robust multivariate regression model.\n",
    "The algorithm calculates least square solutions on subsets with size n_subsamples of the samples in X. Any value of n_subsamples between the number of features and samples leads to an estimator with a compromise between robustness and efficiency. Since the number of least square solutions is “n_samples choose n_subsamples”, it can be extremely large and can therefore be limited with max_subpopulation. If this limit is reached, the subsets are chosen randomly. In a final step, the spatial median (or L1 median) is calculated of all least square solutions. (http://scikit-learn.org/stable/auto_examples/linear_model/plot_theilsen.html#sphx-glr-auto-examples-linear-model-plot-theilsen-py)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for data data_x01.xlsx: 0.43 (+/- 0.56)\n",
      "Accuracy for data data_x3.xlsx: -0.56 (+/- 0.83)\n",
      "Accuracy for data data_x5.xlsx: -1.35 (+/- 2.65)\n",
      "Accuracy for data data_x7.xlsx: -1.12 (+/- 1.11)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import TheilSenRegressor\n",
    "\n",
    "for n in neighborhoods:\n",
    "    X, y = load_data('data/' + n)\n",
    "    tsr = TheilSenRegressor(random_state=42)\n",
    "    scores = cross_val_score(tsr, X, y, cv=3)\n",
    "    print(\"Accuracy for data %s: %0.2f (+/- %0.2f)\" % (n, scores.mean(), scores.std() * 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lasso\n",
    "\n",
    "The Lasso is a linear model that estimates sparse coefficients. It is useful in some contexts due to its tendency to prefer solutions with fewer parameter values, effectively reducing the number of variables upon which the given solution is dependent. (http://scikit-learn.org/stable/auto_examples/applications/plot_tomography_l1_reconstruction.html#sphx-glr-auto-examples-applications-plot-tomography-l1-reconstruction-py)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for data data_x01.xlsx: 0.56 (+/- 0.27)\n",
      "Accuracy for data data_x3.xlsx: 0.53 (+/- 0.23)\n",
      "Accuracy for data data_x5.xlsx: 0.42 (+/- 0.16)\n",
      "Accuracy for data data_x7.xlsx: 0.48 (+/- 0.32)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "for n in neighborhoods:\n",
    "    X, y = load_data('data/' + n)\n",
    "    lasso = Lasso(alpha=10.)\n",
    "    scores = cross_val_score(lasso, X, y, cv=3)\n",
    "    print(\"Accuracy for data %s: %0.2f (+/- %0.2f)\" % (n, scores.mean(), scores.std() * 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
